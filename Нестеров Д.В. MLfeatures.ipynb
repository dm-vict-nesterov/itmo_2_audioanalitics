{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bb0fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import matplotlib as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import soundfile as sf\n",
    "from scipy.io.wavfile import write\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import fft\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fabd14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.24.2)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (5.1.0)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.2.2.tar.gz (323 kB)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.54.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (21.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (1.20.3)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.45.1->librosa) (0.37.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from numba>=0.45.1->librosa) (58.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->librosa) (3.0.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (2.26.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n",
      "Requirement already satisfied: six>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
      "Building wheels for collected packages: audioread, resampy\n",
      "  Building wheel for audioread (setup.py): started\n",
      "  Building wheel for audioread (setup.py): finished with status 'done'\n",
      "  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23154 sha256=54d1efd9556640d893154740b63a450ec03881c549bfac6ef807349c0ac181a5\n",
      "  Stored in directory: c:\\users\\nesterov-dv\\appdata\\local\\pip\\cache\\wheels\\a2\\a3\\bd\\ec1568ce7515115a11ab686d509ad302124c782af065de47ee\n",
      "  Building wheel for resampy (setup.py): started\n",
      "  Building wheel for resampy (setup.py): finished with status 'done'\n",
      "  Created wheel for resampy: filename=resampy-0.2.2-py3-none-any.whl size=320731 sha256=89dd3c932449ca1ca5858581e67a8c053d3ed7d86e8cefc4b5918a631b109c4d\n",
      "  Stored in directory: c:\\users\\nesterov-dv\\appdata\\local\\pip\\cache\\wheels\\86\\2c\\7d\\46a32a246b0e5939cea2c5ec1492164073e0c5d16d666ae2cd\n",
      "Successfully built audioread resampy\n",
      "Installing collected packages: resampy, pooch, audioread, librosa\n",
      "Successfully installed audioread-2.1.9 librosa-0.9.2 pooch-1.6.0 resampy-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23cda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tempfile, os, zipfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path = \"C:/Users/nesterov-dv/Downloads/audio_train/train\"\n",
    "files = os.listdir(path)\n",
    "zero = []\n",
    "for filename in glob.glob(os.path.join(path, '*.wav')):\n",
    "    samplerate, data = scipy.io.wavfile.read(filename)\n",
    "    zero.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f8842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5683"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero)\n",
    "#загружено  записи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc819826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x324 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samplerate: 22050, Length of wav: 103194\n"
     ]
    }
   ],
   "source": [
    "#посмотрим на данные на примере одной записи\n",
    "\n",
    "path_file = r\"C:\\Users\\nesterov-dv\\Downloads\\audio_train\\train\\0a0a60cf2e02c62197e7.wav\"\n",
    "wav, sr = librosa.load(path_file)\n",
    "librosa.display.waveshow(wav, sr=sr)\n",
    "plt.figure(figsize=(15, 4.5))\n",
    "plt.show()\n",
    "ipd.Audio(wav, rate=sr)\n",
    "\n",
    "print('Samplerate: {}, Length of wav: {}'.format(sr, len(wav)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e35c7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=pd.read_csv(r\"C:\\Users\\nesterov-dv\\Downloads\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "623f6571",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/nesterov-dv/Downloads/audio_train/train\"\n",
    "a=[path]*5683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2965113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"link\"]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea0a8a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/nesterov-dv/Downloads/audio_train/train/8bcbcc394ba64fe85ed4.wav'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[\"link1\"] = train_labels[\"link\"].astype(str) + \"/\" + train_labels[\"fname\"].astype(str).str.zfill(6)\n",
    "train_labels[\"link1\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7056c01c",
   "metadata": {},
   "source": [
    "# Извлечение признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b24b1",
   "metadata": {},
   "source": [
    "1. mfcc\n",
    "2. mel-значения в дБ\n",
    "3. zero crossing rate (zcr)\n",
    "4. хроматограмма по сигналам\n",
    "5. спектральные центроиды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69a5c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py:88: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "chroma_stft_val=[]\n",
    "mel=[]\n",
    "mel_db=[]\n",
    "mfcc_val=[]\n",
    "spec_centroid =[]\n",
    "for i in range(len(train_labels)):\n",
    "    x,sr=librosa.load(train_labels[\"link1\"].iloc[i], mono=True)   \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "    chroma_stft_val.append(np.mean(chroma_stft))\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "    mfcc.mean(axis=1)\n",
    "    mfcc_val.append(mfcc.mean(axis=1))\n",
    "    \n",
    "    \n",
    "    spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "    spec_centroid.append(np.mean(spec_cent))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9946b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"chroma_stft.mean\"]=chroma_stft_val\n",
    "train_labels[\"spec_cent.mean\"]=spec_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a764713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.asarray(mfcc_val)\n",
    "MFCC_DF = pd.DataFrame(arr, columns = ['MFCC1','MFCC2','MFCC3','MFCC4','MFCC5','MFCC6','MFCC7','MFCC8','MFCC9','MFCC10','MFCC11','MFCC12','MFCC13','MFCC14','MFCC15','MFCC16','MFCC17','MFCC18','MFCC19','MFCC20',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1e1a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=pd.concat([train_labels, MFCC_DF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1beaad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_db=[]\n",
    "mel=[]\n",
    "zcr_val=[]\n",
    "for i in range(len(train_labels)):\n",
    "        x,sr=librosa.load(train_labels[\"link1\"].iloc[i], mono=True)   \n",
    "\n",
    "        mels=librosa.feature.melspectrogram(y=x, sr=sr, n_mels=128,\n",
    "                                    fmax=8000)\n",
    "        mels_db = librosa.amplitude_to_db(mels)\n",
    "        mel.append(mels.mean(axis=1))\n",
    "        mel_db.append(mels_db.mean(axis=1))\n",
    "\n",
    "\n",
    "        zcr = librosa.feature.zero_crossing_rate(x)\n",
    "        zcr_val.append(np.mean(zcr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49ddd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"mean_zcr\"]=zcr_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "082884d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_db=np.asarray(mel_db)\n",
    "\n",
    "mel_db_df=pd.DataFrame(mel_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4672d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=pd.concat([train_labels, mel_db_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38fbcec",
   "metadata": {},
   "source": [
    "# Разделение на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3539dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=pd.read_csv(r\"C:\\Users\\nesterov-dv\\Downloads\\extracted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b931dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft.mean</th>\n",
       "      <th>spec_cent.mean</th>\n",
       "      <th>MFCC1</th>\n",
       "      <th>MFCC2</th>\n",
       "      <th>MFCC3</th>\n",
       "      <th>MFCC4</th>\n",
       "      <th>MFCC5</th>\n",
       "      <th>MFCC6</th>\n",
       "      <th>MFCC7</th>\n",
       "      <th>MFCC8</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.599837</td>\n",
       "      <td>3236.617813</td>\n",
       "      <td>-544.60270</td>\n",
       "      <td>41.559383</td>\n",
       "      <td>-54.300285</td>\n",
       "      <td>50.719670</td>\n",
       "      <td>-22.157557</td>\n",
       "      <td>22.945400</td>\n",
       "      <td>-19.005857</td>\n",
       "      <td>18.260895</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.965996</td>\n",
       "      <td>-64.644806</td>\n",
       "      <td>-65.072890</td>\n",
       "      <td>-62.285380</td>\n",
       "      <td>-60.558900</td>\n",
       "      <td>-59.522102</td>\n",
       "      <td>-60.111885</td>\n",
       "      <td>-63.460530</td>\n",
       "      <td>-67.033900</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.641052</td>\n",
       "      <td>2384.953258</td>\n",
       "      <td>-445.07477</td>\n",
       "      <td>77.769160</td>\n",
       "      <td>-20.973577</td>\n",
       "      <td>44.579628</td>\n",
       "      <td>-22.406464</td>\n",
       "      <td>27.424837</td>\n",
       "      <td>-9.946759</td>\n",
       "      <td>12.112359</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.651577</td>\n",
       "      <td>-44.538197</td>\n",
       "      <td>-44.534203</td>\n",
       "      <td>-44.705677</td>\n",
       "      <td>-44.620200</td>\n",
       "      <td>-44.545370</td>\n",
       "      <td>-44.809338</td>\n",
       "      <td>-44.834286</td>\n",
       "      <td>-44.834286</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412584</td>\n",
       "      <td>597.493549</td>\n",
       "      <td>-317.91843</td>\n",
       "      <td>186.538070</td>\n",
       "      <td>27.002405</td>\n",
       "      <td>-20.485870</td>\n",
       "      <td>7.619408</td>\n",
       "      <td>20.530241</td>\n",
       "      <td>4.875048</td>\n",
       "      <td>-4.836398</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>-12.288696</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.222431</td>\n",
       "      <td>2038.193140</td>\n",
       "      <td>-380.04865</td>\n",
       "      <td>84.650390</td>\n",
       "      <td>-55.757427</td>\n",
       "      <td>33.086727</td>\n",
       "      <td>-33.839180</td>\n",
       "      <td>10.950944</td>\n",
       "      <td>-26.757208</td>\n",
       "      <td>-2.559376</td>\n",
       "      <td>...</td>\n",
       "      <td>-40.206140</td>\n",
       "      <td>-40.242462</td>\n",
       "      <td>-40.232212</td>\n",
       "      <td>-40.204845</td>\n",
       "      <td>-40.200060</td>\n",
       "      <td>-40.242462</td>\n",
       "      <td>-40.242462</td>\n",
       "      <td>-40.242462</td>\n",
       "      <td>-40.242462</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.360137</td>\n",
       "      <td>2374.571479</td>\n",
       "      <td>-400.79430</td>\n",
       "      <td>84.682810</td>\n",
       "      <td>-95.998000</td>\n",
       "      <td>3.099290</td>\n",
       "      <td>-29.627249</td>\n",
       "      <td>25.633928</td>\n",
       "      <td>-33.591910</td>\n",
       "      <td>0.158687</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.904648</td>\n",
       "      <td>-50.885254</td>\n",
       "      <td>-51.075428</td>\n",
       "      <td>-51.520664</td>\n",
       "      <td>-51.437546</td>\n",
       "      <td>-51.584442</td>\n",
       "      <td>-51.657120</td>\n",
       "      <td>-51.657120</td>\n",
       "      <td>-51.657120</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>0.247419</td>\n",
       "      <td>724.338533</td>\n",
       "      <td>-448.49274</td>\n",
       "      <td>60.625618</td>\n",
       "      <td>51.651127</td>\n",
       "      <td>41.994620</td>\n",
       "      <td>33.294960</td>\n",
       "      <td>25.561966</td>\n",
       "      <td>19.184006</td>\n",
       "      <td>14.459284</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>-7.598045</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679</th>\n",
       "      <td>0.522650</td>\n",
       "      <td>3762.756240</td>\n",
       "      <td>-324.43490</td>\n",
       "      <td>51.706540</td>\n",
       "      <td>-55.067745</td>\n",
       "      <td>66.330215</td>\n",
       "      <td>-38.977074</td>\n",
       "      <td>45.802532</td>\n",
       "      <td>-28.064903</td>\n",
       "      <td>26.365322</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.645632</td>\n",
       "      <td>-34.060257</td>\n",
       "      <td>-34.921524</td>\n",
       "      <td>-37.048560</td>\n",
       "      <td>-34.324840</td>\n",
       "      <td>-33.505566</td>\n",
       "      <td>-37.769203</td>\n",
       "      <td>-44.281246</td>\n",
       "      <td>-46.124336</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>0.300395</td>\n",
       "      <td>981.572153</td>\n",
       "      <td>-436.01993</td>\n",
       "      <td>134.217420</td>\n",
       "      <td>-7.553867</td>\n",
       "      <td>42.228240</td>\n",
       "      <td>4.197356</td>\n",
       "      <td>8.710498</td>\n",
       "      <td>3.348115</td>\n",
       "      <td>24.033790</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>-42.716103</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5681</th>\n",
       "      <td>0.446443</td>\n",
       "      <td>3260.841544</td>\n",
       "      <td>-387.63757</td>\n",
       "      <td>51.981007</td>\n",
       "      <td>-23.477228</td>\n",
       "      <td>34.043400</td>\n",
       "      <td>-32.502323</td>\n",
       "      <td>22.189080</td>\n",
       "      <td>-22.679450</td>\n",
       "      <td>7.896717</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.810210</td>\n",
       "      <td>-31.332430</td>\n",
       "      <td>-31.476343</td>\n",
       "      <td>-31.296663</td>\n",
       "      <td>-32.176613</td>\n",
       "      <td>-32.179405</td>\n",
       "      <td>-33.233162</td>\n",
       "      <td>-36.357240</td>\n",
       "      <td>-36.357240</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5682</th>\n",
       "      <td>0.507987</td>\n",
       "      <td>3050.623803</td>\n",
       "      <td>-253.84969</td>\n",
       "      <td>87.361330</td>\n",
       "      <td>-45.153194</td>\n",
       "      <td>47.233200</td>\n",
       "      <td>-48.920020</td>\n",
       "      <td>29.253044</td>\n",
       "      <td>-34.366400</td>\n",
       "      <td>14.816806</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.162243</td>\n",
       "      <td>-22.107141</td>\n",
       "      <td>-24.729187</td>\n",
       "      <td>-26.300230</td>\n",
       "      <td>-27.527912</td>\n",
       "      <td>-28.223059</td>\n",
       "      <td>-29.276234</td>\n",
       "      <td>-30.647324</td>\n",
       "      <td>-30.815977</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5683 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chroma_stft.mean  spec_cent.mean      MFCC1       MFCC2      MFCC3  \\\n",
       "0             0.599837     3236.617813 -544.60270   41.559383 -54.300285   \n",
       "1             0.641052     2384.953258 -445.07477   77.769160 -20.973577   \n",
       "2             0.412584      597.493549 -317.91843  186.538070  27.002405   \n",
       "3             0.222431     2038.193140 -380.04865   84.650390 -55.757427   \n",
       "4             0.360137     2374.571479 -400.79430   84.682810 -95.998000   \n",
       "...                ...             ...        ...         ...        ...   \n",
       "5678          0.247419      724.338533 -448.49274   60.625618  51.651127   \n",
       "5679          0.522650     3762.756240 -324.43490   51.706540 -55.067745   \n",
       "5680          0.300395      981.572153 -436.01993  134.217420  -7.553867   \n",
       "5681          0.446443     3260.841544 -387.63757   51.981007 -23.477228   \n",
       "5682          0.507987     3050.623803 -253.84969   87.361330 -45.153194   \n",
       "\n",
       "          MFCC4      MFCC5      MFCC6      MFCC7      MFCC8  ...        119  \\\n",
       "0     50.719670 -22.157557  22.945400 -19.005857  18.260895  ... -62.965996   \n",
       "1     44.579628 -22.406464  27.424837  -9.946759  12.112359  ... -44.651577   \n",
       "2    -20.485870   7.619408  20.530241   4.875048  -4.836398  ... -12.288696   \n",
       "3     33.086727 -33.839180  10.950944 -26.757208  -2.559376  ... -40.206140   \n",
       "4      3.099290 -29.627249  25.633928 -33.591910   0.158687  ... -50.904648   \n",
       "...         ...        ...        ...        ...        ...  ...        ...   \n",
       "5678  41.994620  33.294960  25.561966  19.184006  14.459284  ...  -7.598045   \n",
       "5679  66.330215 -38.977074  45.802532 -28.064903  26.365322  ... -28.645632   \n",
       "5680  42.228240   4.197356   8.710498   3.348115  24.033790  ... -42.716103   \n",
       "5681  34.043400 -32.502323  22.189080 -22.679450   7.896717  ... -31.810210   \n",
       "5682  47.233200 -48.920020  29.253044 -34.366400  14.816806  ... -20.162243   \n",
       "\n",
       "            120        121        122        123        124        125  \\\n",
       "0    -64.644806 -65.072890 -62.285380 -60.558900 -59.522102 -60.111885   \n",
       "1    -44.538197 -44.534203 -44.705677 -44.620200 -44.545370 -44.809338   \n",
       "2    -12.288696 -12.288696 -12.288696 -12.288696 -12.288696 -12.288696   \n",
       "3    -40.242462 -40.232212 -40.204845 -40.200060 -40.242462 -40.242462   \n",
       "4    -50.885254 -51.075428 -51.520664 -51.437546 -51.584442 -51.657120   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "5678  -7.598045  -7.598045  -7.598045  -7.598045  -7.598045  -7.598045   \n",
       "5679 -34.060257 -34.921524 -37.048560 -34.324840 -33.505566 -37.769203   \n",
       "5680 -42.716103 -42.716103 -42.716103 -42.716103 -42.716103 -42.716103   \n",
       "5681 -31.332430 -31.476343 -31.296663 -32.176613 -32.179405 -33.233162   \n",
       "5682 -22.107141 -24.729187 -26.300230 -27.527912 -28.223059 -29.276234   \n",
       "\n",
       "            126        127  label_num  \n",
       "0    -63.460530 -67.033900         16  \n",
       "1    -44.834286 -44.834286         34  \n",
       "2    -12.288696 -12.288696         14  \n",
       "3    -40.242462 -40.242462         22  \n",
       "4    -51.657120 -51.657120         33  \n",
       "...         ...        ...        ...  \n",
       "5678  -7.598045  -7.598045          6  \n",
       "5679 -44.281246 -46.124336         32  \n",
       "5680 -42.716103 -42.716103          6  \n",
       "5681 -36.357240 -36.357240         33  \n",
       "5682 -30.647324 -30.815977         15  \n",
       "\n",
       "[5683 rows x 152 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=train_labels.loc[:,\"chroma_stft.mean\":]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258fd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализуем\n",
    "from sklearn import preprocessing\n",
    "minmax=preprocessing.MinMaxScaler()\n",
    "X=minmax.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4318c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"label\"] = pd.Categorical(train_labels[\"label\"])\n",
    "train_labels['label_num'] = train_labels[\"label\"].cat.codes\n",
    "y=train_labels['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d78ae514",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03491cb",
   "metadata": {},
   "source": [
    "# Обучение и тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e946a551",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4599eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ff85379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  0  0 ...  0  0  0]\n",
      " [ 0 22  3 ...  0  0  0]\n",
      " [ 1  2 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 32 12  2]\n",
      " [ 0  0  0 ...  3 20  1]\n",
      " [ 0  0  0 ...  3  0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92        46\n",
      "           1       0.85      0.85      0.85        26\n",
      "           2       0.65      0.54      0.59        24\n",
      "           3       0.84      0.98      0.90        43\n",
      "           4       0.84      0.62      0.71        26\n",
      "           5       0.86      0.60      0.71        10\n",
      "           6       0.69      0.58      0.63        38\n",
      "           7       0.80      0.25      0.38        16\n",
      "           8       0.59      0.92      0.72        24\n",
      "           9       0.50      0.47      0.48        17\n",
      "          10       0.61      0.71      0.65        24\n",
      "          11       0.54      0.68      0.60        22\n",
      "          12       0.70      0.94      0.80        35\n",
      "          13       0.00      0.00      0.00        16\n",
      "          14       0.47      0.50      0.48        16\n",
      "          15       0.53      0.70      0.60        40\n",
      "          16       0.55      0.85      0.67        13\n",
      "          17       0.50      0.68      0.58        38\n",
      "          18       0.87      0.69      0.77        48\n",
      "          19       1.00      0.14      0.25        14\n",
      "          20       0.46      0.53      0.49        40\n",
      "          21       0.55      0.27      0.36        22\n",
      "          22       0.75      0.56      0.64        16\n",
      "          23       0.74      0.74      0.74        39\n",
      "          24       1.00      0.40      0.57        15\n",
      "          25       0.44      0.73      0.55        22\n",
      "          26       0.50      0.77      0.61        35\n",
      "          27       0.50      0.04      0.07        25\n",
      "          28       0.71      0.24      0.36        21\n",
      "          29       0.63      0.92      0.75        26\n",
      "          30       0.68      0.72      0.70        36\n",
      "          31       0.50      0.18      0.27        11\n",
      "          32       0.51      0.68      0.58        38\n",
      "          33       0.45      0.65      0.53        34\n",
      "          34       0.50      0.34      0.41        38\n",
      "          35       0.72      0.77      0.74        30\n",
      "          36       0.60      0.50      0.55        30\n",
      "          37       1.00      0.05      0.10        19\n",
      "          38       0.67      0.62      0.64        52\n",
      "          39       0.49      0.83      0.62        24\n",
      "          40       0.58      0.64      0.61        28\n",
      "\n",
      "    accuracy                           0.63      1137\n",
      "   macro avg       0.64      0.58      0.57      1137\n",
      "weighted avg       0.65      0.63      0.60      1137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "svm_class=svm.SVC()\n",
    "svm_class.fit(X_train, y_train)\n",
    "y_pred=svm_class.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c577a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.347 total time=   2.5s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.372 total time=   2.4s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.331 total time=   2.3s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.348 total time=   2.3s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.331 total time=   2.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.219 total time=   2.5s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.224 total time=   2.2s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.205 total time=   2.3s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.219 total time=   2.2s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.188 total time=   2.1s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.058 total time=   2.3s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.054 total time=   2.3s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.045 total time=   2.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.052 total time=   2.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.061 total time=   2.3s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.035 total time=   2.4s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.034 total time=   2.4s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.034 total time=   2.4s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.034 total time=   2.4s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.057 total time=   2.5s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.035 total time=   2.4s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.034 total time=   2.2s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.034 total time=   2.4s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.034 total time=   2.4s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.057 total time=   2.4s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.686 total time=   2.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.660 total time=   2.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.648 total time=   2.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.636 total time=   2.3s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.656 total time=   1.9s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.559 total time=   1.7s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.552 total time=   1.7s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.546 total time=   1.6s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.528 total time=   1.7s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.559 total time=   1.7s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.262 total time=   2.3s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.248 total time=   2.3s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.240 total time=   2.3s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.246 total time=   2.3s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.229 total time=   2.2s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.064 total time=   2.4s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.054 total time=   2.4s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.053 total time=   2.4s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.050 total time=   2.6s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.059 total time=   2.4s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.035 total time=   2.4s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.034 total time=   2.5s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.034 total time=   2.4s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.034 total time=   2.4s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.057 total time=   2.5s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.785 total time=   2.1s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.754 total time=   2.0s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.776 total time=   2.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14952/3125850701.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# fitting the model for grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[0;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ef999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=0.01)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37f919da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  0  1 ...  0  0  0]\n",
      " [ 1 24  1 ...  0  0  0]\n",
      " [ 1  1 20 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 45  3  1]\n",
      " [ 0  0  0 ...  3 19  1]\n",
      " [ 0  0  0 ...  2  0 26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        46\n",
      "           1       0.89      0.92      0.91        26\n",
      "           2       0.69      0.83      0.75        24\n",
      "           3       0.93      0.93      0.93        43\n",
      "           4       0.90      0.69      0.78        26\n",
      "           5       0.57      0.80      0.67        10\n",
      "           6       0.82      0.84      0.83        38\n",
      "           7       0.67      0.38      0.48        16\n",
      "           8       0.92      1.00      0.96        24\n",
      "           9       0.85      0.65      0.73        17\n",
      "          10       0.79      0.92      0.85        24\n",
      "          11       0.91      0.91      0.91        22\n",
      "          12       0.95      1.00      0.97        35\n",
      "          13       0.94      1.00      0.97        16\n",
      "          14       0.87      0.81      0.84        16\n",
      "          15       0.95      0.97      0.96        40\n",
      "          16       1.00      0.92      0.96        13\n",
      "          17       0.90      0.95      0.92        38\n",
      "          18       0.96      0.90      0.92        48\n",
      "          19       0.88      1.00      0.93        14\n",
      "          20       0.78      0.88      0.82        40\n",
      "          21       1.00      0.73      0.84        22\n",
      "          22       0.81      0.81      0.81        16\n",
      "          23       0.94      0.87      0.91        39\n",
      "          24       0.86      0.80      0.83        15\n",
      "          25       0.81      0.95      0.88        22\n",
      "          26       0.86      0.89      0.87        35\n",
      "          27       0.84      0.84      0.84        25\n",
      "          28       1.00      0.90      0.95        21\n",
      "          29       0.88      0.88      0.88        26\n",
      "          30       0.91      0.86      0.89        36\n",
      "          31       1.00      0.55      0.71        11\n",
      "          32       0.83      0.89      0.86        38\n",
      "          33       0.74      0.85      0.79        34\n",
      "          34       0.85      0.89      0.87        38\n",
      "          35       0.87      0.87      0.87        30\n",
      "          36       0.90      0.90      0.90        30\n",
      "          37       0.75      0.47      0.58        19\n",
      "          38       0.82      0.87      0.84        52\n",
      "          39       0.79      0.79      0.79        24\n",
      "          40       0.93      0.93      0.93        28\n",
      "\n",
      "    accuracy                           0.87      1137\n",
      "   macro avg       0.87      0.85      0.85      1137\n",
      "weighted avg       0.87      0.87      0.87      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_class=svm.SVC(C=1000, gamma=0.01)\n",
    "svm_class.fit(X_train, y_train)\n",
    "y_pred=svm_class.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "f1_svm=f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031da734",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b4bb057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bee1e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46  0  0 ...  0  0  0]\n",
      " [ 0 26  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 52  0  0]\n",
      " [ 0  0  0 ...  0 24  0]\n",
      " [ 0  0  0 ...  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       1.00      1.00      1.00        26\n",
      "           2       1.00      1.00      1.00        24\n",
      "           3       1.00      1.00      1.00        43\n",
      "           4       1.00      1.00      1.00        26\n",
      "           5       1.00      1.00      1.00        10\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      1.00      1.00        16\n",
      "           8       1.00      1.00      1.00        24\n",
      "           9       1.00      1.00      1.00        17\n",
      "          10       1.00      1.00      1.00        24\n",
      "          11       1.00      1.00      1.00        22\n",
      "          12       1.00      1.00      1.00        35\n",
      "          13       1.00      1.00      1.00        16\n",
      "          14       1.00      1.00      1.00        16\n",
      "          15       1.00      1.00      1.00        40\n",
      "          16       1.00      1.00      1.00        13\n",
      "          17       1.00      1.00      1.00        38\n",
      "          18       1.00      1.00      1.00        48\n",
      "          19       1.00      1.00      1.00        14\n",
      "          20       1.00      1.00      1.00        40\n",
      "          21       1.00      1.00      1.00        22\n",
      "          22       1.00      1.00      1.00        16\n",
      "          23       1.00      1.00      1.00        39\n",
      "          24       1.00      1.00      1.00        15\n",
      "          25       1.00      1.00      1.00        22\n",
      "          26       1.00      1.00      1.00        35\n",
      "          27       1.00      1.00      1.00        25\n",
      "          28       1.00      1.00      1.00        21\n",
      "          29       1.00      1.00      1.00        26\n",
      "          30       1.00      1.00      1.00        36\n",
      "          31       1.00      1.00      1.00        11\n",
      "          32       1.00      1.00      1.00        38\n",
      "          33       1.00      1.00      1.00        34\n",
      "          34       1.00      1.00      1.00        38\n",
      "          35       1.00      1.00      1.00        30\n",
      "          36       1.00      1.00      1.00        30\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        52\n",
      "          39       1.00      1.00      1.00        24\n",
      "          40       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00      1137\n",
      "   macro avg       1.00      1.00      1.00      1137\n",
      "weighted avg       1.00      1.00      1.00      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_class=tree.DecisionTreeClassifier()\n",
    "tree_class.fit(X_train, y_train)\n",
    "y_pred=tree_class.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "f1_tree=f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0f7eb4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=5, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=6, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=7, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=8, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=gini, max_depth=9, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=auto;, score=0.089 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=auto;, score=0.101 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=auto;, score=0.106 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=auto;, score=0.125 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=auto;, score=0.079 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.100 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.067 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.112 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.069 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.076 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=log2;, score=0.079 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=log2;, score=0.055 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=log2;, score=0.106 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=log2;, score=0.090 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=5, max_features=log2;, score=0.086 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=auto;, score=0.104 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=auto;, score=0.095 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=auto;, score=0.101 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=auto;, score=0.109 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=auto;, score=0.085 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.121 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.121 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.075 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.051 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.101 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=log2;, score=0.053 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=log2;, score=0.073 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=log2;, score=0.074 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=log2;, score=0.070 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=6, max_features=log2;, score=0.098 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=auto;, score=0.085 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=auto;, score=0.102 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=auto;, score=0.086 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=auto;, score=0.079 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=auto;, score=0.087 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.112 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.096 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.090 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.099 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.105 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=log2;, score=0.089 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=log2;, score=0.097 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=log2;, score=0.079 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=log2;, score=0.092 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=7, max_features=log2;, score=0.072 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=auto;, score=0.071 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=auto;, score=0.092 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=auto;, score=0.119 total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=auto;, score=0.090 total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=auto;, score=0.066 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.075 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.079 total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.085 total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.095 total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.110 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=log2;, score=0.111 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=log2;, score=0.086 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=log2;, score=0.105 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=log2;, score=0.088 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=8, max_features=log2;, score=0.076 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=auto;, score=0.078 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=auto;, score=0.073 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=auto;, score=0.100 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=auto;, score=0.077 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=auto;, score=0.095 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.084 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.091 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.088 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.102 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.048 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=log2;, score=0.102 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=log2;, score=0.065 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=log2;, score=0.087 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=log2;, score=0.076 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.1, criterion=entropy, max_depth=9, max_features=log2;, score=0.081 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=auto;, score=0.066 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=sqrt;, score=0.063 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=5, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=6, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=sqrt;, score=0.062 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=sqrt;, score=0.062 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=log2;, score=0.066 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=7, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=auto;, score=0.062 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=auto;, score=0.058 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=sqrt;, score=0.062 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=sqrt;, score=0.063 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=8, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=auto;, score=0.034 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=auto;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=sqrt;, score=0.062 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=sqrt;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=sqrt;, score=0.063 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=sqrt;, score=0.061 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=sqrt;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=log2;, score=0.034 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=log2;, score=0.068 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=gini, max_depth=9, max_features=log2;, score=0.035 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=auto;, score=0.200 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=auto;, score=0.166 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=auto;, score=0.187 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=auto;, score=0.197 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=auto;, score=0.184 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.222 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.190 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.166 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.196 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.185 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=log2;, score=0.178 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=log2;, score=0.158 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=log2;, score=0.156 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=log2;, score=0.152 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=5, max_features=log2;, score=0.187 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=auto;, score=0.214 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=auto;, score=0.202 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=auto;, score=0.206 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=auto;, score=0.212 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=auto;, score=0.200 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.214 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.204 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.215 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.190 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.213 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=log2;, score=0.184 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=log2;, score=0.207 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=log2;, score=0.194 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=log2;, score=0.177 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=6, max_features=log2;, score=0.182 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=auto;, score=0.233 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=auto;, score=0.212 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=auto;, score=0.243 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=auto;, score=0.179 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=auto;, score=0.216 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.209 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.220 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.219 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.204 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.212 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=log2;, score=0.225 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=log2;, score=0.221 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=log2;, score=0.194 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=log2;, score=0.183 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=7, max_features=log2;, score=0.190 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=auto;, score=0.237 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=auto;, score=0.211 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=auto;, score=0.218 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=auto;, score=0.220 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=auto;, score=0.209 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.231 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.219 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.279 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.196 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.200 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=log2;, score=0.207 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=log2;, score=0.205 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=log2;, score=0.207 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=log2;, score=0.175 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=8, max_features=log2;, score=0.187 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=auto;, score=0.231 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=auto;, score=0.228 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=auto;, score=0.218 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=auto;, score=0.224 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=auto;, score=0.183 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.213 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.226 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.204 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.233 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.201 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=log2;, score=0.169 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=log2;, score=0.235 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=log2;, score=0.185 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=log2;, score=0.193 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.01, criterion=entropy, max_depth=9, max_features=log2;, score=0.200 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=auto;, score=0.211 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=auto;, score=0.169 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=auto;, score=0.168 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=auto;, score=0.186 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=auto;, score=0.168 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=sqrt;, score=0.186 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=sqrt;, score=0.189 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=sqrt;, score=0.188 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=sqrt;, score=0.174 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=sqrt;, score=0.144 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=log2;, score=0.164 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=log2;, score=0.144 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=log2;, score=0.138 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=log2;, score=0.150 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=5, max_features=log2;, score=0.171 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=auto;, score=0.195 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=auto;, score=0.175 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=auto;, score=0.186 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=auto;, score=0.180 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=auto;, score=0.179 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=sqrt;, score=0.221 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=sqrt;, score=0.190 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=sqrt;, score=0.220 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=sqrt;, score=0.206 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=sqrt;, score=0.160 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=log2;, score=0.176 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=log2;, score=0.210 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=log2;, score=0.176 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=log2;, score=0.179 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=6, max_features=log2;, score=0.169 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=auto;, score=0.220 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=auto;, score=0.204 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=auto;, score=0.222 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=auto;, score=0.194 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=auto;, score=0.218 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=sqrt;, score=0.202 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=sqrt;, score=0.187 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=sqrt;, score=0.189 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=sqrt;, score=0.179 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=sqrt;, score=0.215 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=log2;, score=0.203 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=log2;, score=0.220 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=log2;, score=0.185 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=log2;, score=0.204 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=7, max_features=log2;, score=0.187 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=auto;, score=0.246 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=auto;, score=0.223 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=auto;, score=0.208 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=auto;, score=0.213 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=auto;, score=0.197 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=sqrt;, score=0.212 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=sqrt;, score=0.218 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=sqrt;, score=0.232 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=sqrt;, score=0.228 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=sqrt;, score=0.205 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=log2;, score=0.192 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=log2;, score=0.160 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=log2;, score=0.254 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=log2;, score=0.197 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=8, max_features=log2;, score=0.155 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=auto;, score=0.238 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=auto;, score=0.232 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=auto;, score=0.207 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=auto;, score=0.229 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=auto;, score=0.216 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=sqrt;, score=0.232 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=sqrt;, score=0.216 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=sqrt;, score=0.218 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=sqrt;, score=0.220 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=sqrt;, score=0.195 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=log2;, score=0.231 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=log2;, score=0.208 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=log2;, score=0.245 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=log2;, score=0.210 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=gini, max_depth=9, max_features=log2;, score=0.205 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=auto;, score=0.160 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=auto;, score=0.172 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=auto;, score=0.187 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=auto;, score=0.142 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=auto;, score=0.173 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.169 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.191 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.156 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.190 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=sqrt;, score=0.208 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=log2;, score=0.182 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=log2;, score=0.200 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=log2;, score=0.144 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=log2;, score=0.190 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=5, max_features=log2;, score=0.122 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=auto;, score=0.230 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=auto;, score=0.219 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=auto;, score=0.222 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=auto;, score=0.223 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=auto;, score=0.199 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.207 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.213 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.197 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.197 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=sqrt;, score=0.162 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=log2;, score=0.216 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=log2;, score=0.179 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=log2;, score=0.188 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=log2;, score=0.197 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=6, max_features=log2;, score=0.191 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=auto;, score=0.227 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=auto;, score=0.221 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=auto;, score=0.233 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=auto;, score=0.257 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=auto;, score=0.209 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.231 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.235 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.239 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.217 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=sqrt;, score=0.213 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=log2;, score=0.245 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=log2;, score=0.197 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=log2;, score=0.197 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=log2;, score=0.209 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=7, max_features=log2;, score=0.195 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=auto;, score=0.276 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=auto;, score=0.229 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=auto;, score=0.240 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=auto;, score=0.229 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=auto;, score=0.249 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.268 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.252 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.248 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.239 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=sqrt;, score=0.240 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=log2;, score=0.215 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=log2;, score=0.202 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=log2;, score=0.213 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=log2;, score=0.212 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=8, max_features=log2;, score=0.175 total time=   0.1s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=auto;, score=0.262 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=auto;, score=0.275 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=auto;, score=0.251 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=auto;, score=0.235 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=auto;, score=0.202 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.295 total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.233 total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.263 total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.235 total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=sqrt;, score=0.242 total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=log2;, score=0.238 total time=   0.1s\n",
      "[CV 2/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=log2;, score=0.215 total time=   0.1s\n",
      "[CV 3/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=log2;, score=0.211 total time=   0.1s\n",
      "[CV 4/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=log2;, score=0.210 total time=   0.1s\n",
      "[CV 5/5] END ccp_alpha=0.001, criterion=entropy, max_depth=9, max_features=log2;, score=0.215 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'ccp_alpha': [0.1, 0.01, 0.001],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [5, 6, 7, 8, 9],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'ccp_alpha': [0.1, .01, .001],\n",
    "              'max_depth' : [5, 6, 7, 8, 9],\n",
    "              'criterion' :['gini', 'entropy']\n",
    "             }\n",
    "\n",
    "\n",
    "grid1 = GridSearchCV(tree.DecisionTreeClassifier(), param_grid, refit = True, verbose = 3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "abe64bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.001, 'criterion': 'entropy', 'max_depth': 9, 'max_features': 'sqrt'}\n",
      "DecisionTreeClassifier(ccp_alpha=0.001, criterion='entropy', max_depth=9,\n",
      "                       max_features='sqrt')\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid1.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf381269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24  0  9 ...  0  0  0]\n",
      " [ 0 17  1 ...  0  0  0]\n",
      " [ 2  4 12 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 21  4  0]\n",
      " [ 0  0  0 ...  2  6  1]\n",
      " [ 0  0  0 ...  3  1  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56        46\n",
      "           1       0.50      0.65      0.57        26\n",
      "           2       0.43      0.50      0.46        24\n",
      "           3       0.95      0.86      0.90        43\n",
      "           4       0.17      0.19      0.18        26\n",
      "           5       0.50      0.50      0.50        10\n",
      "           6       0.32      0.26      0.29        38\n",
      "           7       0.50      0.19      0.27        16\n",
      "           8       0.22      0.46      0.30        24\n",
      "           9       0.33      0.12      0.17        17\n",
      "          10       0.14      0.25      0.18        24\n",
      "          11       0.44      0.36      0.40        22\n",
      "          12       0.53      0.57      0.55        35\n",
      "          13       0.55      0.38      0.44        16\n",
      "          14       0.26      0.31      0.29        16\n",
      "          15       0.59      0.65      0.62        40\n",
      "          16       0.70      0.54      0.61        13\n",
      "          17       0.50      0.34      0.41        38\n",
      "          18       0.43      0.31      0.36        48\n",
      "          19       0.44      0.50      0.47        14\n",
      "          20       0.27      0.30      0.29        40\n",
      "          21       0.29      0.27      0.28        22\n",
      "          22       0.40      0.12      0.19        16\n",
      "          23       0.42      0.44      0.43        39\n",
      "          24       0.27      0.20      0.23        15\n",
      "          25       0.35      0.50      0.42        22\n",
      "          26       0.18      0.20      0.19        35\n",
      "          27       0.24      0.20      0.22        25\n",
      "          28       1.00      0.05      0.09        21\n",
      "          29       0.36      0.73      0.48        26\n",
      "          30       0.51      0.53      0.52        36\n",
      "          31       0.00      0.00      0.00        11\n",
      "          32       0.33      0.32      0.32        38\n",
      "          33       0.17      0.24      0.20        34\n",
      "          34       0.06      0.03      0.04        38\n",
      "          35       0.61      0.57      0.59        30\n",
      "          36       0.07      0.10      0.08        30\n",
      "          37       0.40      0.21      0.28        19\n",
      "          38       0.43      0.40      0.42        52\n",
      "          39       0.19      0.25      0.22        24\n",
      "          40       0.28      0.32      0.30        28\n",
      "\n",
      "    accuracy                           0.37      1137\n",
      "   macro avg       0.39      0.35      0.35      1137\n",
      "weighted avg       0.40      0.37      0.37      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_class=tree.DecisionTreeClassifier(ccp_alpha=0.001, criterion='entropy', max_depth=9,\n",
    "                       max_features='sqrt')\n",
    "tree_class.fit(X_train, y_train)\n",
    "y_pred=tree_class.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "f1_tree=f1_score(y_test, y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1addbf7",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8559f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44  2  0 ...  0  0  0]\n",
      " [ 0 26  0 ...  0  0  0]\n",
      " [ 1  1 16 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 32  1  0]\n",
      " [ 0  0  0 ...  1 19  1]\n",
      " [ 0  0  0 ...  1  1 25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        46\n",
      "           1       0.81      1.00      0.90        26\n",
      "           2       0.84      0.67      0.74        24\n",
      "           3       0.84      0.98      0.90        43\n",
      "           4       0.88      0.54      0.67        26\n",
      "           5       0.50      0.50      0.50        10\n",
      "           6       0.68      0.74      0.71        38\n",
      "           7       0.67      0.25      0.36        16\n",
      "           8       0.61      0.79      0.69        24\n",
      "           9       0.55      0.35      0.43        17\n",
      "          10       0.63      0.79      0.70        24\n",
      "          11       0.73      0.73      0.73        22\n",
      "          12       0.67      1.00      0.80        35\n",
      "          13       0.62      0.50      0.55        16\n",
      "          14       0.46      0.69      0.55        16\n",
      "          15       0.51      0.70      0.59        40\n",
      "          16       0.71      0.77      0.74        13\n",
      "          17       0.55      0.68      0.61        38\n",
      "          18       0.71      0.60      0.65        48\n",
      "          19       0.67      0.86      0.75        14\n",
      "          20       0.70      0.53      0.60        40\n",
      "          21       0.54      0.32      0.40        22\n",
      "          22       0.67      0.62      0.65        16\n",
      "          23       0.73      0.82      0.77        39\n",
      "          24       0.83      0.33      0.48        15\n",
      "          25       0.36      0.59      0.45        22\n",
      "          26       0.57      0.69      0.62        35\n",
      "          27       0.67      0.16      0.26        25\n",
      "          28       0.56      0.24      0.33        21\n",
      "          29       0.57      0.92      0.71        26\n",
      "          30       0.69      0.75      0.72        36\n",
      "          31       0.43      0.27      0.33        11\n",
      "          32       0.61      0.71      0.66        38\n",
      "          33       0.57      0.74      0.64        34\n",
      "          34       0.45      0.26      0.33        38\n",
      "          35       0.92      0.80      0.86        30\n",
      "          36       0.69      0.73      0.71        30\n",
      "          37       1.00      0.21      0.35        19\n",
      "          38       0.78      0.62      0.69        52\n",
      "          39       0.66      0.79      0.72        24\n",
      "          40       0.86      0.89      0.88        28\n",
      "\n",
      "    accuracy                           0.67      1137\n",
      "   macro avg       0.67      0.64      0.63      1137\n",
      "weighted avg       0.68      0.67      0.65      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_f=RandomForestClassifier()\n",
    "rand_f.fit(X_train, y_train)\n",
    "y_pred=rand_f.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "f1_rand=f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af16f4",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12c0055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  0  0 ...  0  0  0]\n",
      " [ 0 24  2 ...  0  0  0]\n",
      " [ 1  6  8 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 27  2  1]\n",
      " [ 0  0  0 ...  1 11  1]\n",
      " [ 0  0  0 ...  1  0  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        46\n",
      "           1       0.62      0.92      0.74        26\n",
      "           2       0.57      0.33      0.42        24\n",
      "           3       0.81      0.98      0.88        43\n",
      "           4       0.76      0.62      0.68        26\n",
      "           5       0.36      0.40      0.38        10\n",
      "           6       0.48      0.39      0.43        38\n",
      "           7       0.83      0.31      0.45        16\n",
      "           8       0.50      0.50      0.50        24\n",
      "           9       0.42      0.29      0.34        17\n",
      "          10       0.56      0.58      0.57        24\n",
      "          11       0.46      0.73      0.56        22\n",
      "          12       0.51      0.83      0.63        35\n",
      "          13       0.35      0.56      0.43        16\n",
      "          14       0.47      0.50      0.48        16\n",
      "          15       0.44      0.50      0.47        40\n",
      "          16       0.67      0.62      0.64        13\n",
      "          17       0.48      0.58      0.52        38\n",
      "          18       0.57      0.54      0.55        48\n",
      "          19       0.53      0.64      0.58        14\n",
      "          20       0.50      0.35      0.41        40\n",
      "          21       0.35      0.36      0.36        22\n",
      "          22       0.71      0.31      0.43        16\n",
      "          23       0.72      0.72      0.72        39\n",
      "          24       0.50      0.27      0.35        15\n",
      "          25       0.31      0.50      0.39        22\n",
      "          26       0.31      0.54      0.40        35\n",
      "          27       0.33      0.20      0.25        25\n",
      "          28       0.28      0.24      0.26        21\n",
      "          29       0.43      0.58      0.49        26\n",
      "          30       0.70      0.39      0.50        36\n",
      "          31       0.20      0.18      0.19        11\n",
      "          32       0.39      0.61      0.47        38\n",
      "          33       0.50      0.62      0.55        34\n",
      "          34       0.23      0.16      0.19        38\n",
      "          35       0.81      0.70      0.75        30\n",
      "          36       0.40      0.47      0.43        30\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.73      0.52      0.61        52\n",
      "          39       0.79      0.46      0.58        24\n",
      "          40       0.64      0.32      0.43        28\n",
      "\n",
      "    accuracy                           0.52      1137\n",
      "   macro avg       0.51      0.49      0.49      1137\n",
      "weighted avg       0.53      0.52      0.51      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0792692c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'leaf_size': (20, 40, 1),\n",
       "                         'metric': ('minkowski', 'chebyshev'),\n",
       "                         'n_neighbors': (1, 10, 1), 'p': (1, 2),\n",
       "                         'weights': ('uniform', 'distance')},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters= {\n",
    "    'n_neighbors': (1,10, 1),\n",
    "    'leaf_size': (20,40,1),\n",
    "    'p': (1,2),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    'metric': ('minkowski', 'chebyshev')}\n",
    "                   \n",
    "# with GridSearch\n",
    "grid = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "    param_grid=parameters,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = -1,\n",
    "    cv = 5)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9acf6f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 20, 'metric': 'chebyshev', 'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}\n",
      "KNeighborsClassifier(leaf_size=20, metric='chebyshev', n_neighbors=1, p=1)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "723d81f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  2  1 ...  0  0  0]\n",
      " [ 0 25  1 ...  0  0  0]\n",
      " [ 2  2 12 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 35  5  0]\n",
      " [ 0  0  0 ...  3 14  1]\n",
      " [ 0  0  0 ...  2  0 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80        46\n",
      "           1       0.68      0.96      0.79        26\n",
      "           2       0.63      0.50      0.56        24\n",
      "           3       0.88      0.88      0.88        43\n",
      "           4       0.78      0.54      0.64        26\n",
      "           5       0.41      0.70      0.52        10\n",
      "           6       0.70      0.61      0.65        38\n",
      "           7       0.78      0.44      0.56        16\n",
      "           8       0.68      0.71      0.69        24\n",
      "           9       0.54      0.41      0.47        17\n",
      "          10       0.48      0.62      0.55        24\n",
      "          11       0.74      0.77      0.76        22\n",
      "          12       0.71      0.91      0.80        35\n",
      "          13       0.42      0.81      0.55        16\n",
      "          14       0.47      0.50      0.48        16\n",
      "          15       0.70      0.57      0.63        40\n",
      "          16       0.77      0.77      0.77        13\n",
      "          17       0.64      0.66      0.65        38\n",
      "          18       0.63      0.56      0.59        48\n",
      "          19       0.73      0.79      0.76        14\n",
      "          20       0.71      0.60      0.65        40\n",
      "          21       0.56      0.45      0.50        22\n",
      "          22       0.56      0.56      0.56        16\n",
      "          23       0.79      0.77      0.78        39\n",
      "          24       0.73      0.53      0.62        15\n",
      "          25       0.52      0.59      0.55        22\n",
      "          26       0.40      0.49      0.44        35\n",
      "          27       0.38      0.40      0.39        25\n",
      "          28       0.22      0.19      0.21        21\n",
      "          29       0.63      0.73      0.68        26\n",
      "          30       0.56      0.53      0.54        36\n",
      "          31       0.20      0.18      0.19        11\n",
      "          32       0.48      0.53      0.50        38\n",
      "          33       0.61      0.79      0.69        34\n",
      "          34       0.38      0.34      0.36        38\n",
      "          35       0.87      0.67      0.75        30\n",
      "          36       0.48      0.70      0.57        30\n",
      "          37       0.71      0.26      0.38        19\n",
      "          38       0.71      0.67      0.69        52\n",
      "          39       0.61      0.58      0.60        24\n",
      "          40       0.77      0.61      0.68        28\n",
      "\n",
      "    accuracy                           0.62      1137\n",
      "   macro avg       0.61      0.60      0.60      1137\n",
      "weighted avg       0.63      0.62      0.62      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(leaf_size=20, metric='chebyshev', n_neighbors=1, p=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "f1_knn=f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c704c1",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "975ab9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  1  0 ...  0  0  0]\n",
      " [ 0 23  2 ...  0  0  0]\n",
      " [ 2  2  9 ...  0  0  1]\n",
      " ...\n",
      " [ 0  0  0 ... 10 13  6]\n",
      " [ 0  0  0 ...  4  7  3]\n",
      " [ 0  0  0 ...  2  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        46\n",
      "           1       0.72      0.88      0.79        26\n",
      "           2       0.82      0.38      0.51        24\n",
      "           3       0.75      0.93      0.83        43\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.38      0.26      0.31        38\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.37      0.62      0.46        24\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.18      0.08      0.11        24\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.32      0.80      0.46        35\n",
      "          13       0.00      0.00      0.00        16\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.29      0.72      0.41        40\n",
      "          16       0.50      0.15      0.24        13\n",
      "          17       0.15      0.13      0.14        38\n",
      "          18       0.38      0.52      0.44        48\n",
      "          19       0.00      0.00      0.00        14\n",
      "          20       0.23      0.17      0.20        40\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       0.00      0.00      0.00        16\n",
      "          23       0.32      0.51      0.40        39\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.25      0.32      0.28        22\n",
      "          26       0.25      0.34      0.29        35\n",
      "          27       0.00      0.00      0.00        25\n",
      "          28       0.00      0.00      0.00        21\n",
      "          29       0.39      0.58      0.47        26\n",
      "          30       0.27      0.56      0.36        36\n",
      "          31       0.00      0.00      0.00        11\n",
      "          32       0.26      0.50      0.35        38\n",
      "          33       0.44      0.56      0.49        34\n",
      "          34       0.12      0.03      0.04        38\n",
      "          35       0.27      0.60      0.37        30\n",
      "          36       0.43      0.10      0.16        30\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.42      0.19      0.26        52\n",
      "          39       0.17      0.29      0.21        24\n",
      "          40       0.13      0.43      0.21        28\n",
      "\n",
      "    accuracy                           0.35      1137\n",
      "   macro avg       0.24      0.28      0.24      1137\n",
      "weighted avg       0.29      0.35      0.30      1137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB=MultinomialNB()\n",
    "NB.fit(X_train,y_train)\n",
    "y_pred=NB.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ea614911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=MultinomialNB(), n_jobs=-1,\n",
       "             param_grid={'alpha': (1, 0.1, 0.01, 0.001, 0.0001)}, verbose=1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_nb = {\n",
    "    'alpha': (1, 0.1, 0.01, 0.001, 0.0001)\n",
    "}\n",
    "\n",
    "nbModel_grid = GridSearchCV(estimator=MultinomialNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "nbModel_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2b9a980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n",
      "MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(nbModel_grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(nbModel_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd266637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40  1  0 ...  0  0  0]\n",
      " [ 0 22  2 ...  0  0  0]\n",
      " [ 1  2 10 ...  0  0  1]\n",
      " ...\n",
      " [ 0  0  0 ... 10 13  6]\n",
      " [ 0  0  0 ...  4  6  3]\n",
      " [ 0  0  0 ...  2  0 12]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92        46\n",
      "           1       0.73      0.85      0.79        26\n",
      "           2       0.83      0.42      0.56        24\n",
      "           3       0.75      0.93      0.83        43\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.40      0.26      0.32        38\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.38      0.62      0.47        24\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.14      0.08      0.11        24\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.33      0.80      0.47        35\n",
      "          13       0.00      0.00      0.00        16\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.28      0.72      0.41        40\n",
      "          16       0.60      0.23      0.33        13\n",
      "          17       0.15      0.13      0.14        38\n",
      "          18       0.40      0.54      0.46        48\n",
      "          19       0.00      0.00      0.00        14\n",
      "          20       0.21      0.15      0.17        40\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       0.00      0.00      0.00        16\n",
      "          23       0.31      0.51      0.39        39\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.24      0.32      0.27        22\n",
      "          26       0.26      0.37      0.31        35\n",
      "          27       0.00      0.00      0.00        25\n",
      "          28       0.00      0.00      0.00        21\n",
      "          29       0.39      0.58      0.47        26\n",
      "          30       0.28      0.56      0.37        36\n",
      "          31       0.00      0.00      0.00        11\n",
      "          32       0.26      0.50      0.34        38\n",
      "          33       0.44      0.56      0.49        34\n",
      "          34       0.10      0.03      0.04        38\n",
      "          35       0.27      0.57      0.37        30\n",
      "          36       0.43      0.10      0.16        30\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.40      0.19      0.26        52\n",
      "          39       0.14      0.25      0.18        24\n",
      "          40       0.14      0.43      0.21        28\n",
      "\n",
      "    accuracy                           0.35      1137\n",
      "   macro avg       0.24      0.28      0.24      1137\n",
      "weighted avg       0.29      0.35      0.30      1137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "NB=MultinomialNB(alpha=0.1)\n",
    "NB.fit(X_train,y_train)\n",
    "y_pred=NB.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "f1_nb=f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5f93f",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43abb97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 46  0 ...  0  0  0]\n",
      " [ 0 26  0 ...  0  0  0]\n",
      " [ 0  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 52  0  0]\n",
      " [ 0  0  0 ...  0 24  0]\n",
      " [ 0  0  0 ...  0  0 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        46\n",
      "           1       0.36      1.00      0.53        26\n",
      "           2       1.00      1.00      1.00        24\n",
      "           3       0.00      0.00      0.00        43\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.32      1.00      0.49        38\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.60      1.00      0.75        24\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.59      1.00      0.74        24\n",
      "          11       1.00      1.00      1.00        22\n",
      "          12       1.00      1.00      1.00        35\n",
      "          13       1.00      1.00      1.00        16\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.06      1.00      0.12        40\n",
      "          16       0.00      0.00      0.00        13\n",
      "          17       0.00      0.00      0.00        38\n",
      "          18       0.00      0.00      0.00        48\n",
      "          19       0.00      0.00      0.00        14\n",
      "          20       0.00      0.00      0.00        40\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       0.00      0.00      0.00        16\n",
      "          23       0.00      0.00      0.00        39\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.00      0.00      0.00        22\n",
      "          26       0.00      0.00      0.00        35\n",
      "          27       0.00      0.00      0.00        25\n",
      "          28       0.00      0.00      0.00        21\n",
      "          29       0.00      0.00      0.00        26\n",
      "          30       0.00      0.00      0.00        36\n",
      "          31       0.00      0.00      0.00        11\n",
      "          32       0.00      0.00      0.00        38\n",
      "          33       0.00      0.00      0.00        34\n",
      "          34       0.00      0.00      0.00        38\n",
      "          35       0.00      0.00      0.00        30\n",
      "          36       0.00      0.00      0.00        30\n",
      "          37       1.00      1.00      1.00        19\n",
      "          38       1.00      1.00      1.00        52\n",
      "          39       1.00      1.00      1.00        24\n",
      "          40       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           0.33      1137\n",
      "   macro avg       0.24      0.32      0.26      1137\n",
      "weighted avg       0.24      0.33      0.26      1137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adabclass=AdaBoostClassifier()\n",
    "adabclass.fit(X_train,y_train)\n",
    "y_pred=adabclass.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "f1_adab=f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3c7bada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
       "                         'n_estimators': [10, 50, 100, 500]},\n",
       "             scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\" : [10, 50, 100, 500],\n",
    "              \"learning_rate\" :   [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "              \n",
    "             }\n",
    "\n",
    "gridC = GridSearchCV(estimator=adabclass, param_grid=param_grid, verbose=3,scoring='f1',n_jobs=-1)\n",
    "gridC.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8c362b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0001, 'n_estimators': 10}\n",
      "AdaBoostClassifier(learning_rate=0.0001, n_estimators=10)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(gridC.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(gridC.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1772c162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 46  0 ...  0  0  0]\n",
      " [ 0 26  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        46\n",
      "           1       0.36      1.00      0.53        26\n",
      "           2       0.00      0.00      0.00        24\n",
      "           3       0.00      0.00      0.00        43\n",
      "           4       0.00      0.00      0.00        26\n",
      "           5       0.00      0.00      0.00        10\n",
      "           6       0.00      0.00      0.00        38\n",
      "           7       0.00      0.00      0.00        16\n",
      "           8       0.00      0.00      0.00        24\n",
      "           9       0.00      0.00      0.00        17\n",
      "          10       0.00      0.00      0.00        24\n",
      "          11       0.00      0.00      0.00        22\n",
      "          12       0.03      1.00      0.06        35\n",
      "          13       0.00      0.00      0.00        16\n",
      "          14       0.00      0.00      0.00        16\n",
      "          15       0.00      0.00      0.00        40\n",
      "          16       0.00      0.00      0.00        13\n",
      "          17       0.00      0.00      0.00        38\n",
      "          18       0.00      0.00      0.00        48\n",
      "          19       0.00      0.00      0.00        14\n",
      "          20       0.00      0.00      0.00        40\n",
      "          21       0.00      0.00      0.00        22\n",
      "          22       0.00      0.00      0.00        16\n",
      "          23       0.00      0.00      0.00        39\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.00      0.00      0.00        22\n",
      "          26       0.00      0.00      0.00        35\n",
      "          27       0.00      0.00      0.00        25\n",
      "          28       0.00      0.00      0.00        21\n",
      "          29       0.00      0.00      0.00        26\n",
      "          30       0.00      0.00      0.00        36\n",
      "          31       0.00      0.00      0.00        11\n",
      "          32       0.00      0.00      0.00        38\n",
      "          33       0.00      0.00      0.00        34\n",
      "          34       0.00      0.00      0.00        38\n",
      "          35       0.00      0.00      0.00        30\n",
      "          36       0.00      0.00      0.00        30\n",
      "          37       0.00      0.00      0.00        19\n",
      "          38       0.00      0.00      0.00        52\n",
      "          39       0.00      0.00      0.00        24\n",
      "          40       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.05      1137\n",
      "   macro avg       0.01      0.05      0.01      1137\n",
      "weighted avg       0.01      0.05      0.01      1137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "adabclass=AdaBoostClassifier(learning_rate=0.0001, n_estimators=10)\n",
    "adabclass.fit(X_train,y_train)\n",
    "y_pred=adabclass.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ac71d",
   "metadata": {},
   "source": [
    "QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acb8f058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0 ...  0  1  0]\n",
      " [ 0 18  1 ...  0  0  0]\n",
      " [ 0  1  9 ...  0  0  0]\n",
      " ...\n",
      " [ 2  0  1 ... 20  0  0]\n",
      " [ 0  0  0 ...  1  9  0]\n",
      " [ 0  0  0 ...  0  0 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.41      0.44        46\n",
      "           1       0.72      0.69      0.71        26\n",
      "           2       0.30      0.38      0.33        24\n",
      "           3       0.67      0.77      0.72        43\n",
      "           4       0.62      0.62      0.62        26\n",
      "           5       0.26      0.60      0.36        10\n",
      "           6       0.63      0.50      0.56        38\n",
      "           7       0.50      0.19      0.27        16\n",
      "           8       0.35      0.54      0.43        24\n",
      "           9       0.28      0.29      0.29        17\n",
      "          10       0.37      0.54      0.44        24\n",
      "          11       0.38      0.68      0.49        22\n",
      "          12       0.59      0.69      0.63        35\n",
      "          13       0.15      0.12      0.14        16\n",
      "          14       0.22      0.25      0.24        16\n",
      "          15       0.33      0.23      0.27        40\n",
      "          16       0.38      0.69      0.49        13\n",
      "          17       0.27      0.45      0.34        38\n",
      "          18       0.47      0.56      0.51        48\n",
      "          19       0.56      0.64      0.60        14\n",
      "          20       0.54      0.38      0.44        40\n",
      "          21       0.43      0.14      0.21        22\n",
      "          22       0.47      0.44      0.45        16\n",
      "          23       0.71      0.51      0.60        39\n",
      "          24       0.40      0.40      0.40        15\n",
      "          25       0.22      0.45      0.30        22\n",
      "          26       0.38      0.54      0.45        35\n",
      "          27       0.50      0.24      0.32        25\n",
      "          28       0.40      0.19      0.26        21\n",
      "          29       0.50      0.58      0.54        26\n",
      "          30       0.59      0.44      0.51        36\n",
      "          31       0.18      0.18      0.18        11\n",
      "          32       0.33      0.45      0.38        38\n",
      "          33       0.43      0.47      0.45        34\n",
      "          34       0.20      0.13      0.16        38\n",
      "          35       0.84      0.70      0.76        30\n",
      "          36       0.50      0.37      0.42        30\n",
      "          37       0.44      0.21      0.29        19\n",
      "          38       0.67      0.38      0.49        52\n",
      "          39       0.60      0.38      0.46        24\n",
      "          40       0.37      0.36      0.36        28\n",
      "\n",
      "    accuracy                           0.45      1137\n",
      "   macro avg       0.44      0.43      0.42      1137\n",
      "weighted avg       0.47      0.45      0.44      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import discriminant_analysis\n",
    "clf = discriminant_analysis.LinearDiscriminantAnalysis(solver=\"lsqr\")\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "f1_qda=f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd7089",
   "metadata": {},
   "source": [
    "Сводная таблица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "419b289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_df=[[\"svm\", f1_svm], [\"Decision tree\", f1_tree], [\"Random forest\", f1_rand], [\"KNN\", f1_knn], [\"Naive bayes\", f1_nb], [\"Adaptive Boosting\", f1_adab], [\"QDA\", f1_qda]]\n",
    "f1_score_df=pd.DataFrame(f1_score_df,columns=[\"Method\", \"Macro F1-score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "428f6e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Macro F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.851304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.348636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random forest</td>\n",
       "      <td>0.626712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.595786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive bayes</td>\n",
       "      <td>0.239799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adaptive Boosting</td>\n",
       "      <td>0.259167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.421600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Method  Macro F1-score\n",
       "0                svm        0.851304\n",
       "1      Decision tree        0.348636\n",
       "2      Random forest        0.626712\n",
       "3                KNN        0.595786\n",
       "4        Naive bayes        0.239799\n",
       "5  Adaptive Boosting        0.259167\n",
       "6                QDA        0.421600"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
